{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fb944e-56df-4a12-bb0e-4af493f12d94",
   "metadata": {},
   "source": [
    "## Corner with SubPixel Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020f6b49-34c8-4e2f-b002-00ae92db0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a004a8-328e-404c-a4a4-c23ada4cabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Images/chessboard.jpg'\n",
    "output_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefe517a-2937-4386-881c-38809c67605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to: results\\chessboard.jpg\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, os.path.basename(filename))\n",
    "\n",
    "img = cv.imread(filename)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Image not found at {filename}\")\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gray_f = np.float32(gray)\n",
    "\n",
    "dst = cv.cornerHarris(gray_f, 2, 3, 0.04)\n",
    "dst = cv.dilate(dst, None)\n",
    "\n",
    "_, dst = cv.threshold(dst, 0.01 * dst.max(), 255, 0)\n",
    "dst = np.uint8(dst)\n",
    "\n",
    "_, labels, stats, centroids = cv.connectedComponentsWithStats(dst)\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "corners = cv.cornerSubPix(gray_f, np.float32(centroids), (5, 5), (-1, -1), criteria)\n",
    "\n",
    "res_centroids = np.int32(centroids)\n",
    "res_corners = np.int32(corners)\n",
    "\n",
    "for i in range(len(res_centroids)):\n",
    "    cv.circle(img, (res_centroids[i, 0], res_centroids[i, 1]), 2, (0, 0, 255), -1)\n",
    "    cv.circle(img, (res_corners[i, 0], res_corners[i, 1]), 2, (0, 255, 0), -1)\n",
    "\n",
    "cv.imwrite(output_path, img)\n",
    "print(f\"Image saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86cdf87-509a-4c32-b9e0-e59990e779a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed images saved in Images/\n",
      "Harris results saved in results/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "input_image_path = \"Images/image4.jpg\"\n",
    "images_dir = \"Images\"\n",
    "results_dir = \"results\"\n",
    "\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "img = cv.imread(input_image_path)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Image not found at {input_image_path}\")\n",
    "\n",
    "H, W = img.shape[:2]\n",
    "\n",
    "# ----------------------------\n",
    "# Harris Corner Detection\n",
    "# ----------------------------\n",
    "def apply_harris(bgr_img: np.ndarray, scale_factor: float = 1.0) -> np.ndarray:\n",
    "    out = bgr_img.copy()\n",
    "    gray = cv.cvtColor(out, cv.COLOR_BGR2GRAY)\n",
    "    gray_f = np.float32(gray)\n",
    "    \n",
    "    # Scale-adaptive parameters\n",
    "    block_size = max(2, int(2 * scale_factor))\n",
    "    ksize = max(3, int(3 * scale_factor))\n",
    "    if ksize % 2 == 0:  # ksize must be odd\n",
    "        ksize += 1\n",
    "    \n",
    "    dst = cv.cornerHarris(gray_f, block_size, ksize, 0.04)\n",
    "    dst = cv.dilate(dst, None)\n",
    "\n",
    "    _, dst_thr = cv.threshold(dst, 0.01 * dst.max(), 255, 0)\n",
    "    dst_thr = np.uint8(dst_thr)\n",
    "\n",
    "    _, labels, stats, centroids = cv.connectedComponentsWithStats(dst_thr)\n",
    "\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv.cornerSubPix(gray_f, np.float32(centroids), (5, 5), (-1, -1), criteria)\n",
    "\n",
    "    centroids_i = np.int32(centroids)\n",
    "    corners_i = np.int32(corners)\n",
    "\n",
    "    for i in range(len(centroids_i)):\n",
    "        cv.circle(out, tuple(centroids_i[i]), 2, (0, 0, 255), -1)  # red: centroid\n",
    "        cv.circle(out, tuple(corners_i[i]), 2, (0, 255, 0), -1)    # green: refined\n",
    "\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: center crop to (H, W)\n",
    "# ----------------------------\n",
    "def center_crop(bgr_img: np.ndarray, target_h: int, target_w: int) -> np.ndarray:\n",
    "    h, w = bgr_img.shape[:2]\n",
    "    if h < target_h or w < target_w:\n",
    "        raise ValueError(\"Cannot center-crop because image is smaller than target size.\")\n",
    "\n",
    "    y0 = (h - target_h) // 2\n",
    "    x0 = (w - target_w) // 2\n",
    "    return bgr_img[y0:y0 + target_h, x0:x0 + target_w]\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: pad to (H, W) (for zoom-out)\n",
    "# ----------------------------\n",
    "def pad_to_size(bgr_img: np.ndarray, target_h: int, target_w: int,\n",
    "                border_type=cv.BORDER_CONSTANT, value=(0, 0, 0)) -> np.ndarray:\n",
    "    h, w = bgr_img.shape[:2]\n",
    "    if h > target_h or w > target_w:\n",
    "        raise ValueError(\"Cannot pad because image is larger than target size. Crop instead.\")\n",
    "\n",
    "    top = (target_h - h) // 2\n",
    "    bottom = target_h - h - top\n",
    "    left = (target_w - w) // 2\n",
    "    right = target_w - w - left\n",
    "\n",
    "    return cv.copyMakeBorder(bgr_img, top, bottom, left, right, border_type, value=value)\n",
    "\n",
    "# ----------------------------\n",
    "# Same-size Zoom In (scale up then crop)\n",
    "# ----------------------------\n",
    "def zoom_in_same_size(bgr_img: np.ndarray, scale: float, target_h: int, target_w: int) -> np.ndarray:\n",
    "    if scale <= 1.0:\n",
    "        raise ValueError(\"zoom_in_same_size requires scale > 1.0\")\n",
    "\n",
    "    interp = cv.INTER_CUBIC\n",
    "    scaled = cv.resize(bgr_img, None, fx=scale, fy=scale, interpolation=interp)\n",
    "    return center_crop(scaled, target_h, target_w)\n",
    "\n",
    "# ----------------------------\n",
    "# Same-size Zoom Out (scale down then pad)\n",
    "# ----------------------------\n",
    "def zoom_out_same_size(bgr_img: np.ndarray, scale: float, target_h: int, target_w: int) -> np.ndarray:\n",
    "    if scale >= 1.0:\n",
    "        raise ValueError(\"zoom_out_same_size requires scale < 1.0\")\n",
    "\n",
    "    interp = cv.INTER_AREA\n",
    "    scaled = cv.resize(bgr_img, None, fx=scale, fy=scale, interpolation=interp)\n",
    "\n",
    "    # You MUST pad to keep same size; \"cut excess\" is not applicable here because it's smaller.\n",
    "    # Choose border type: CONSTANT (black), REPLICATE, REFLECT, etc.\n",
    "    return pad_to_size(scaled, target_h, target_w, border_type=cv.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "# ----------------------------\n",
    "# Same-size Rotate (rotate in-place, then crop to original size automatically)\n",
    "# ----------------------------\n",
    "def rotate_same_size(bgr_img: np.ndarray, angle_deg: float) -> np.ndarray:\n",
    "    h, w = bgr_img.shape[:2]\n",
    "    center = (w / 2.0, h / 2.0)\n",
    "    M = cv.getRotationMatrix2D(center, angle_deg, 1.0)\n",
    "\n",
    "    # warpAffine output size is SAME (w, h) -> corners may be clipped (as you requested: cut excess)\n",
    "    rotated = cv.warpAffine(\n",
    "        bgr_img, M, (w, h),\n",
    "        flags=cv.INTER_LINEAR,\n",
    "        borderMode=cv.BORDER_REPLICATE\n",
    "    )\n",
    "    return rotated\n",
    "\n",
    "# ----------------------------\n",
    "# Create transformed images (SAME SIZE as original)\n",
    "# ----------------------------\n",
    "scale_up_img = zoom_in_same_size(img, scale=4.0, target_h=H, target_w=W)     # zoom in, crop excess\n",
    "scale_down_img = zoom_out_same_size(img, scale=0.5, target_h=H, target_w=W)  # zoom out, pad to size\n",
    "rotated_img = rotate_same_size(img, angle_deg=30)                            # rotate, cut excess\n",
    "\n",
    "# ----------------------------\n",
    "# Save transformed images (Images folder)\n",
    "# ----------------------------\n",
    "cv.imwrite(os.path.join(images_dir, \"scale_up_img1.jpg\"), scale_up_img)\n",
    "cv.imwrite(os.path.join(images_dir, \"scale_down_img1.jpg\"), scale_down_img)\n",
    "cv.imwrite(os.path.join(images_dir, \"rotatted_img1.jpg\"), rotated_img)\n",
    "\n",
    "# ----------------------------\n",
    "# Apply Harris on transformed images\n",
    "# ----------------------------\n",
    "harris_scale_up = apply_harris(scale_up_img)\n",
    "harris_scale_down = apply_harris(scale_down_img)\n",
    "harris_rotated = apply_harris(rotated_img)\n",
    "\n",
    "# ----------------------------\n",
    "# Save results (results folder)\n",
    "# ----------------------------\n",
    "cv.imwrite(os.path.join(results_dir, \"scale_up_img1.jpg\"), harris_scale_up)\n",
    "cv.imwrite(os.path.join(results_dir, \"scale_down_img1.jpg\"), harris_scale_down)\n",
    "cv.imwrite(os.path.join(results_dir, \"rotatted_img1.jpg\"), harris_rotated)\n",
    "\n",
    "print(\"Transformed images saved in Images/\")\n",
    "print(\"Harris results saved in results/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
